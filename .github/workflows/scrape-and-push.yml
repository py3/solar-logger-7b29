name: scrape-and-push

on:
  schedule:
    - cron: "15,45 * * * *"   # 30分ごと
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - uses: actions/checkout@v4
      # pip キャッシュ
      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('gh_pages/requirements.txt') }}

      # Playwright ブラウザキャッシュ
      - name: Cache Playwright browsers
        uses: actions/cache@v4
        with:
          path: ~/.cache/ms-playwright
          key: ${{ runner.os }}-ms-playwright-${{ hashFiles('gh_pages/requirements.txt') }}

      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install deps
        run: |
          python -m pip install -r gh_pages/requirements.txt
          python -m playwright install --with-deps chromium

      - name: Run scraper
        env:
          PV_USERNAME: ${{ secrets.PV_USERNAME }}
          PV_PASSWORD: ${{ secrets.PV_PASSWORD }}
        run: |
          python gh_pages/pv_logger.py

      - name: Commit & push CSV
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add docs/index.html docs/data/pv_log.csv
          git commit -m "Update pv_log.csv [skip ci]" || echo "No changes"
          git push
